
Assignment 3 
GPU: 1060 6GB (1280 CUDA Cores)

--------------------

Step 1 - 3loop_cuda.cu which is standard 3 loop matrix
multiplication running on the GPU (CUDA Cores).

Making sure it computes the correct matrix:

44 48 24 48 19 96 56 56
47 82 54 50 80 65 39 44
34 35 74 13 73 97 78 75
16 99 8 37 52 30 48 95
77 72 94 47 19 1 2 65
35 7 66 14 24 4 57 57
91 82 69 15 31 47 41 46
97 48 82 48 29 30 43 5

x

44 48 24 48 19 96 56 56
47 82 54 50 80 65 39 44
34 35 74 13 73 97 78 75
16 99 8 37 52 30 48 95
77 72 94 47 19 1 2 65
35 7 66 14 24 4 57 57
91 82 69 15 31 47 41 46
97 48 82 48 29 30 43 5

=

21127 20960 22386 12365 14949 15827 18726 20499
24810 27345 28061 16275 19560 20073 19798 25959
29254 24310 33082 14384 17832 19484 21763 24466
24858 25279 24588 15335 16683 15135 15024 17140
18705 22202 20388 14314 18861 24667 19680 20704
17041 15116 17341 8181 10743 15066 13117 13243
22669 23123 24455 14858 18428 24735 20796 22114
17761 22278 19455 12566 16914 24146 19750 23852

All time tests from now on will be with N = 1024
(Average over 10 runs)

To test that computations are correct after optimizations
we change to N = 8 temporarily.
 
Time taken for 3loop Matrix multiplication (CUDA): 
11.7017 milliseconds (0.0117017 seconds)

OPTIMIZATIONS (Problem 2)

Your solution should at least take reasonable steps to deal with 
control/loop divergance, memory coalescing, thread coarsening, 
and privatization. Note that all might not be required or result 
in improvements, but you should at least investigate.



Step 2 - First optimization (opt_cuda_1.cu)
Control/loop divergance fixed with shared memory

Time taken for 3loop Matrix multiplication (CUDA): 
4.85787 milliseconds (0.00485787 seconds)

11.7017 - 4.85787 = 6.84383 milliseconds faster!

TESTED WITH 8x8 test matrix: OK! (Calculations correct)



Step 3 - Second optimization (opt_cuda_2.cu)
Memory coalescing

LINE 32:
mxB_shared[threadIdx.y][threadIdx.x] = d_B[(i * TILE_SIZE + threadIdx.y) * n + col];
=> 
mxB_shared[threadIdx.y][threadIdx.x] = d_B[col + (i * TILE_SIZE + threadIdx.y) * n]; // <------

Time taken for 3loop Matrix multiplication (CUDA): 
4.67498 milliseconds (0.00467498 seconds)

This did little to no difference on the time, however we stick with it.

Since the time difference is really similar we assume the resulting
matrix is correct as well.





Step 4 - Third optimization (opt_cuda_3.cu)
Thread Coarsening

What is it? 
Each thread is assigned to do more work than the basic, 
fine-grained approach. Instead of having one thread handle a 
single data element, a coarsened thread will process 
multiple elements.

Slower: Time taken for 3loop Matrix multiplication (CUDA): 
6.14023 milliseconds (0.00614023 seconds)


Step 5 - Fourth optimization (olpt_cuda_4.cu)
Privatization 

Copying opt_cuda_2 since that is our champion optimization currentlyÂ¨

Privatization def: giving each thread its own private memory space.

Purpose: 
- Reduce shared memory bank conflicts
- Minimize thread synchronization
- Improve parallel computation efficiency
- Decrease memory access latency

Time taken for 3loop Matrix multiplication (CUDA): 
4.71608 milliseconds (0.00471608 seconds)

Which is comparable to opt_cuda_2.cu


CONCLUSION: Control Loop Divergence (Implement shared memory) was
the only optimization that significantly increased computation speed.
